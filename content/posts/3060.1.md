---
title: "💻 CSC3060 Introduction to Computer System"
date: 2026-01-06T10:30:34+08:00
draft: false
summary: "CUHKSZ 大二课程 CSC3060 的第一节课，引入计算机系统中软硬件的基础知识"
categories: 
- SDS
tags: 
- CSC3060
featured_image: "/images/30601.jpg"
---



# CSC3060 Lecture 1

Computer System = **Hardware + System Software**

本科目偏向于软件，比如代码如何被编译，如何优化代码等等。课本为 CS: APP (v3)。

</br>

## 硬件：CPU

- CPU 并非连续运作，而是按照 “fetch, decode, execute” (从内存/缓存取指令、解译命令、运算或访问)的循环周期性工作。最小时间单位为 cycle，以 GHz (频率)计算，比如 3GHz 的 CPU每秒处理 3x10<sup>9</sup> 个 cycle。

- 单核(singular CPU) 是单进程的，通过切换进程实现“并发”。

- CPU 由以下基本部分组成：

  PC (program counter) 是 CPU 的临时存储部件，属于一个特殊的**寄存器**，存储指向主存中某条**命令**的**指针**，同时只能被一个进程的一个命令占用，CPU 处理 PC 指向的命令，然后更新 PC 指向下一个命令……

  Registers 寄存器：存储**一个** **“字”** (即 **n-bit 计算机上的 n bit** 二进制数) 的；

  Register file 寄存器文件：一些通用寄存器组成的临时存储部件，不一定存储指针，它们直接连接着 ALU；

  ALU 是计算与逻辑模块，对寄存器文件的一或多个寄存器的值进行计算；

  bus interface 是 CPU 暴露给总线的接口，用于通信。

![](https://i.postimg.cc/44hwD0VY/jie-ping2026-01-06-18-29-15.png)

</br>

</br>

## 硬件：Bus (总线)

- CPU、内存、I/O 设备都用一系列物理层的导线 “bus” 进行通信，传送 “字” 大小的字节块，常见三类信号：**数据线** (data)、**地址线** (address)、**控制线** (control)。缓慢的访存和更加慢的 I/O 会造成总线“堵车”。这个问题促使 cache、DMA 等技术诞生。

- **Direct Memory Access** 在 “设备 ↔ 内存”之间搬数据，不能执行指令；**能“绕过 CPU 内的总线，但绕不过 I/O 和内存总线”**。

</br>

</br>

## 硬件：记忆分区

### Memory Hierarchy

| **存储类型**          | **访问时间**           |
| --------------------- | ---------------------- |
| L0 Registers 寄存器   | ~1 cycle               |
| L1 Cache              | ~4 cycles              |
| L2 Cache              | ~10 cycles             |
| L4 DRAM 主存 (内存)   | ~100–300 cycles        |
| L5 Local SSD (如磁盘) | ~10<sup>5</sup> cycles |

记忆阶级性 hierarchy：**上层可用作其下层的缓存** (如 DRAM 是 SSD 的缓存区)，从下到上；存储量变小变贵，但速度变快。

分区的原因：主存缓慢、两个局部性、隔离进程

</br>

### 主存 (DRAM)

主存是 CPU 外，临时的存储模块

**为什么主存这么慢？**
**DRAM = Dynamic RAM (动态随机存储器)**：使用**电容**的 “满/空” 表示二进制 bit，电容会漏电，所以必须**周期性刷新 (refresh)**。<u>主存慢、便宜、规模大</u>。

</br>

### CPU 缓存 (SRAM)

 CPU Cache 是**位于 CPU 与主存 (DRAM) 之间的小而快的存储**，SRAM 使用 **flip-flop circuit**  的**双稳态**表示二进制 bit。<u>缓存快、昂贵、规模小</u>。

- 通过把**最可能**用到的数据提前放在 CPU 附近防止缓慢的 DRAM 掐死 CPU 的高速运行。
  所谓“最可能” 的依据： 时间与空间局部性

1. Temporal Locality：访问 A 后的一段时间很可能再次访问 A
2. Spatial Locality：访问 A 后，其邻居，如 A-1、A+1 都很可能被访问

</br>

</br>

## Program Lifetime

1. 源代码(text)：
```c
printf("hello, world\n");
```
2. 编译 (compilation)：
```shell
gcc -o hello hello.c
```
分为四步：
**pre-processor** (macro expansion, process "include")、**compiler** (text→assembly)、**assembler** (assembly→binary)、**linker** (pack object files and libraries into executable)
3. 作为可执行文件储存 (Unix: hello, Linux: hello.exe)
4. 运行：
```shell
./hello
```
以下为具体过程
```pseudocode
┌──────────────────────┐
│        User          │ 物理层：输入 "./hello" shell 命令
└──────────┬───────────┘
┌──────────▼───────────┐
│   Shell (bash/zsh)   │ 应用层：shell (命令解释器) 解析命令并请求 OS 执行
└──────────┬───────────┘
┌──────────▼───────────┐
│   OS Kernel          │ 软件层：OS 内核将数据从 SSD 搬到主存（DMA)
└──────────┬───────────┘
┌──────────▼───────────┐
│   Device Drivers     │ 软硬交界：驱动程序让 OS 可以与硬件通信
└──────────┬───────────┘
┌──────────▼───────────┐
│   Hardware (CPU/IO)  │ 硬件层：CPU 把 "hello, world\n" 搬到寄存器并显示
└──────────-───────────┘
```
- ./hello 键入后，shell 请求 OS 处理这行命令，命令从 I/O 主线经过 I/O 桥再从系统主线进入 CPU 的主线接口，经过内主线存储到寄存器；CPU 接下来直接经过 I/O 桥和内存桥存储 “hello” 到主存；通过 DMA，磁盘 L5 中的 hello 文件按页被临时缓存到主存 L4 ；主存中的命令再被各层 SRAM (cache) 传递到寄存器，并命令 I/O 桥另一侧的显示器显示结果。

![](https://i.postimg.cc/43WsTyCF/tu-xiang.png)

- shell 是连接用户输入和 OS 的软件，Unix: zsh 和 Linux: cmd 都属于不同种类的 shell
- OS 花费很多时间在**搬数据**，而非算术计算
- **主存和寄存器的时间鸿沟**导致 “缓存” 的必要性

</br>

</br>

## 软件：操作系统

OS 是调度并管理硬件资源的软件层，将硬件**抽象**建模为可操作的**虚拟**对象：
1. **Process（进程）**：对 CPU、内存、I/O 的抽象
   - Concurrency：单核处理器通过 **OS kernel** 进行 context switching 实现多线并发(concurrency)，也就是多个进程切换交替占用 CPU。context switching：在每个进程运行时切换到其对应上下文 (参数/环境等等)，实现独占 CPU 的假象。
   - Parallelism：多核处理器可以同时运行多个进程，无需切换
1. **Virtual Memory（虚拟内存）**：对主存+磁盘的抽象， 虚拟地址空间存储**在磁盘上**
   - 虚拟内存的分区是“语义与安全模型”，与硬件层的寄存器、缓存、主存等**毫无对应关系**
```pseudocode
高地址
┌─────────────────┐
│   Kernel Space  │  ← 内核
├─────────────────┤
│      Stack      │  ← 函数调用、局部变量
│        ↓        │
│                 │
│        ↑        │
│      Heap       │  ← malloc / new
├─────────────────┤
│   Data / BSS    │  ← global / static 变量，来自 disk
├─────────────────┤
│   Text          │  ← 程序代码
└─────────────────┘
低地址
```
   - 堆向上分配，栈向下分配，中间是未分配的虚拟地址；虚拟地址空间按 **页 (page)** 管理，**第 0 页 (0x00000000 ～ 0x00000FFF) 不映射到任何物理内存**，这样空指针就不可解指。
   - 虚拟内存通常是按 Byte 寻址，即每次读 8 bits，但也有 word(32b)/double-word(64b)。一台 “n-bit 计算机” 有 2<sup>n</sup> Byte 的理论**虚拟存储空间**。
   - 根据内存阶级性，**L4-DRAM 是 (L5-磁盘) 虚拟内存的缓存**，只保存 “正在用的 page”
   - 虚拟地址空间可以大于物理内存。64-bit 计算机**并没有** 2<sup>64</sup> B 的物理内存。
   - 允许多个进程共享数据：不同进程**虚拟地址不同，可以映射到相同的 DRAM 物理页**，这也是 concurrency 的一种。
3. **File（文件）**：把 I/O 设备抽象为连续的字节

</br>

</br>

## Amdahl's Law

如果一个系统中占比 α 的部分效率提升 k 倍，总效率变化仍显著受剩余部分拖累：
$$T_{new} = (1-\alpha)T_{old} + \frac{\alpha T_{old}}{k},\ \ \text{Speedup} = \frac{1}{(1-\alpha) + \alpha/k}$$
- 优化代码应当优先修改最慢的部分，而不是优化已经较快的字段
- 摩尔定律无法将晶体管数量和计算机效率联系起来，就是因为物理资源的增加和效率没有直接关系
